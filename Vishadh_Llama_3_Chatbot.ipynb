{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vDGRTWpvJknn",
        "outputId": "a4b2266b-7cd9-4cb0-b7f3-9ce12ba5f5ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Welcome to the Llama-3 chat session. Type 'exit' to end the chat.\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import os\n",
        "\n",
        "def get_response_from_llama3(user_input):\n",
        "    \"\"\"\n",
        "    Function to get a response from Llama-3 API.\n",
        "    Replace this function with actual API calls to Llama-3 when available.\n",
        "    \"\"\"\n",
        "    api_url = 'https://api.llama3service.com/v1/generate'  # Replace with actual Llama-3 API endpoint\n",
        "    api_key = os.getenv('LLAMA3_API_KEY')  # Ensure your API key is set in environment variables\n",
        "\n",
        "    headers = {\n",
        "        'Authorization': f'Bearer {api_key}',\n",
        "        'Content-Type': 'application/json'\n",
        "    }\n",
        "\n",
        "    data = {\n",
        "        'prompt': user_input,\n",
        "        'max_tokens': 50,\n",
        "        'temperature': 0.7,\n",
        "        'top_p': 1.0\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        response = requests.post(api_url, headers=headers, json=data)\n",
        "        response.raise_for_status()\n",
        "        return response.json().get('choices', [{}])[0].get('text', 'No response text found.')\n",
        "    except requests.exceptions.HTTPError as http_err:\n",
        "        return f'HTTP error occurred: {http_err}'\n",
        "    except Exception as err:\n",
        "        return f'Other error occurred: {err}'\n",
        "\n",
        "def chat_with_llama3():\n",
        "    \"\"\"\n",
        "    Initiates an infinite chat loop with Llama-3.\n",
        "    Users can type their messages, and the system responds using Llama-3.\n",
        "    \"\"\"\n",
        "    print(\"Welcome to the Llama-3 chat session. Type 'exit' to end the chat.\")\n",
        "\n",
        "    while True:\n",
        "        user_input = input(\"You: \")\n",
        "        if user_input.lower() == 'exit':\n",
        "            print(\"Exiting chat. Goodbye!\")\n",
        "            break\n",
        "\n",
        "        response = get_response_from_llama3(user_input)\n",
        "        print(f\"Llama-3: {response}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    chat_with_llama3()\n"
      ]
    }
  ]
}